daelim.c7zwjferork7.ap-northeast-2.rds.amazonaws.com

daelimc

daelimc1234

1521

DAELIM

DECLARE

hdnl NUMBER;

BEGIN

hdnl := DBMS*DATAPUMP.OPEN( operation => 'EXPORT', job*mode => 'SCHEMA', job_name=>null);

DBMS*DATAPUMP.ADD*FILE( handle => hdnl, filename => 'daelimbackup*20200619*3.dmp', directory => 'DATA*PUMP*DIR', filetype => dbms*datapump.ku$filetype*dump_file);

DBMS*DATAPUMP.ADD*FILE( handle => hdnl, filename => 'exp*20200619*3.log', directory => 'DATA*PUMP*DIR', filetype => dbms*datapump.ku$filetype*log_file);

DBMS*DATAPUMP.METADATA*FILTER(hdnl,'SCHEMA_EXPR','IN (''DAELIMC'')'); -- DAELIM - 사용자이름

DBMS*DATAPUMP.START*JOB(hdnl);

END;

select \* from table(RDSADMIN.RDS*FILE*UTIL.LISTDIR('DATA*PUMP*DIR')) order by mtime;

SELECT rdsadmin.rdsadmin*s3*tasks.upload*to*s3(

p*bucket*name => 'daelimbackup', -- aws s3

p*prefix => 'daelimbackup*20200616', -- 'DATA*PUMP*DIR' 내 파일명

p*s3*prefix => '',

p*directory*name => 'DATA*PUMP*DIR') -- ORACLE Directory 지정

AS TASK_ID FROM DUAL;

SELECT text FROM table(rdsadmin.rds*file*util.read*text*file('BDUMP','dbtask-1592275059939-338.log'));

SELECT rdsadmin.rdsadmin*s3*tasks.upload*to*s3(

p*bucket*name => 'daelimbackup', -- aws s3

p*prefix => 'exp*20200616', -- 'DATA*PUMP*DIR' 내 파일명

p*s3*prefix => '',

p*directory*name => 'DATA*PUMP*DIR') -- ORACLE Directory 지정

AS TASK_ID FROM DUAL;

SELECT text FROM table(rdsadmin.rds*file*util.read*text*file('BDUMP','dbtask-1592275167010-338.log'));